{
  "device": "cuda:1",
  "device_idx": "1",
  "llm_name": "llama-7b",
  "model_name_or_path": "/ssd/public_datasets/llama/llama_to_hf/llama-7b",
  "tokenizer_name_or_path": "/ssd/public_datasets/llama/llama_to_hf/llama-7b",
  "peft_type": "CAUSAL_LM",
  "task_type": "TEXT",
  "num_virtual_tokens": 50,
  "prompt_tuning_init_text": "please generate query for this document",
  "peft_model_id": "llama-7b_CAUSAL_LM_TEXT",
  "prompt_num": 3,
  "text_len": 1024,
  "dataset_name": "ms_50",
  "train_data": "/home/xwu/project/SPTAR/xuyang/data/msmarco_50/prompt_tuning_1000_train_text_sampled.csv",
  "eval_data": "/home/xwu/project/SPTAR/xuyang/data/msmarco_50/prompt_tuning_50_test_text.csv",
  "test_data": "/home/xwu/project/SPTAR/xuyang/data/msmarco_50/prompt_tuning_50_test_text.csv",
  "few_shot_num": 100,
  "fixed_prompt": true,
  "max_length": 1024,
  "lr": 0.03,
  "num_epochs": 100,
  "batch_size": 1,
  "eval_batch_size": 2,
  "checkpoint_name": "ms_50__ssd_public_datasets_llama_llama_to_hf_llama-7b_CAUSAL_LM_TEXT_v1.pt",
  "experiment_dir": "/home/xwu/project/SPTAR/xuyang/llm_models",
  "experiment_description": "v1_pointwise_without_prompt_example_ms_50_llama-7b_llama-7b_CAUSAL_LM_TEXT_50_100_3_fixed_prompt_contractive_hard_10_val_loss"
}